================================================================================
O-MaMa Architecture Timing Profile
================================================================================

HIGH-LEVEL TIMINGS:
--------------------------------------------------------------------------------
data_loading......................................     0.0008 ms
descriptor_extraction_dest........................   702.0821 ms
descriptor_extraction_source......................   390.1532 ms
model_forward.....................................    22.0918 ms
loss_backward.....................................  1318.9603 ms
optimizer_step....................................    22.6218 ms
total_iteration...................................  2467.1000 ms

MODEL FORWARD PASS BREAKDOWN:
--------------------------------------------------------------------------------
extract_object_descriptors........................     0.0249 ms
dest_dense_feats_preparation......................     0.2736 ms
cross_attention_source_to_dest....................     7.8537 ms
source_dense_feats_preparation....................     0.4104 ms
cross_attention_dest_to_source....................    11.3625 ms
mlp_source_descriptors............................     0.4683 ms
mlp_dest_descriptors..............................     0.8188 ms
descriptor_normalization..........................     0.2164 ms
similarity_computation............................     0.1700 ms
best_mask_selection...............................     0.0647 ms
topk_selection....................................     0.0675 ms
full_pred_mask_extraction.........................     0.0356 ms
loss_computation..................................     0.2173 ms
sigmoid_activation................................     0.0476 ms
total_forward_pass................................    22.0502 ms

CROSS ATTENTION MODULE #1 (Source to Dest) BREAKDOWN:
--------------------------------------------------------------------------------
norm_input........................................     1.5041 ms
query_projection..................................     0.0885 ms
key_projection....................................     3.2223 ms
value_projection..................................     2.2000 ms
attention_matmul_and_scale........................     0.2993 ms
attention_softmax.................................     0.0688 ms
attention_weighted_sum............................     0.1591 ms
output_projection.................................     0.0896 ms
residual_add......................................     0.0004 ms
feedforward_mlp...................................     0.1762 ms
total_context_attn................................     7.8267 ms

CROSS ATTENTION MODULE #2 (Dest to Source) BREAKDOWN:
--------------------------------------------------------------------------------
norm_input........................................     0.5184 ms
query_projection..................................     0.3070 ms
key_projection....................................     3.9434 ms
value_projection..................................     3.4002 ms
attention_matmul_and_scale........................     1.7284 ms
attention_softmax.................................     0.2341 ms
attention_weighted_sum............................     0.5065 ms
output_projection.................................     0.1733 ms
residual_add......................................     0.0000 ms
feedforward_mlp...................................     0.5218 ms
total_context_attn................................    11.3420 ms

MLP MODULE TIMINGS:
--------------------------------------------------------------------------------
MLP call #1............................................     0.4304 ms
MLP call #2............................................     0.7647 ms

================================================================================
SUMMARY:
--------------------------------------------------------------------------------
Total iteration time: 2467.1000 ms
Model forward pass: 22.0918 ms (0.9% of total)
Total descriptor extraction: 1092.2353 ms (44.3% of total)
================================================================================