================================================================================
O-MaMa Architecture Timing Profile
================================================================================

HIGH-LEVEL TIMINGS:
--------------------------------------------------------------------------------
data_loading......................................     0.0004 ms
descriptor_extraction_dest........................   374.6438 ms
descriptor_extraction_source......................   208.1819 ms
model_forward.....................................    11.7868 ms
loss_backward.....................................   703.8588 ms
optimizer_step....................................    12.0704 ms
total_iteration...................................  1316.1698 ms

MODEL FORWARD PASS BREAKDOWN:
--------------------------------------------------------------------------------
extract_object_descriptors........................     0.0133 ms
dest_dense_feats_preparation......................     0.1460 ms
cross_attention_source_to_dest....................     4.1909 ms
source_dense_feats_preparation....................     0.2190 ms
cross_attention_dest_to_source....................     6.0637 ms
mlp_source_descriptors............................     0.2499 ms
mlp_dest_descriptors..............................     0.4370 ms
descriptor_normalization..........................     0.1155 ms
similarity_computation............................     0.0907 ms
best_mask_selection...............................     0.0345 ms
topk_selection....................................     0.0360 ms
full_pred_mask_extraction.........................     0.0190 ms
loss_computation..................................     0.1160 ms
sigmoid_activation................................     0.0254 ms
total_forward_pass................................    11.7643 ms

CROSS ATTENTION MODULE #1 (Source to Dest) BREAKDOWN:
--------------------------------------------------------------------------------
norm_input........................................     0.8026 ms
query_projection..................................     0.0472 ms
key_projection....................................     1.7195 ms
value_projection..................................     1.1734 ms
attention_matmul_and_scale........................     0.1597 ms
attention_softmax.................................     0.0367 ms
attention_weighted_sum............................     0.0849 ms
output_projection.................................     0.0478 ms
residual_add......................................     0.0002 ms
feedforward_mlp...................................     0.0940 ms
total_context_attn................................     4.1768 ms

CROSS ATTENTION MODULE #2 (Dest to Source) BREAKDOWN:
--------------------------------------------------------------------------------
norm_input........................................     0.2767 ms
query_projection..................................     0.1638 ms
key_projection....................................     2.1044 ms
value_projection..................................     1.8149 ms
attention_matmul_and_scale........................     0.9223 ms
attention_softmax.................................     0.1249 ms
attention_weighted_sum............................     0.2703 ms
output_projection.................................     0.0925 ms
residual_add......................................     0.0000 ms
feedforward_mlp...................................     0.2785 ms
total_context_attn................................     6.0544 ms

MLP MODULE TIMINGS:
--------------------------------------------------------------------------------
MLP call #1............................................     0.2296 ms
MLP call #2............................................     0.4081 ms

================================================================================
SUMMARY:
--------------------------------------------------------------------------------
Total iteration time: 1316.1698 ms
Model forward pass: 11.7868 ms (0.9% of total)
Total descriptor extraction: 582.8258 ms (44.3% of total)
================================================================================
