================================================================================
O-MaMa Architecture Timing Profile
================================================================================

HIGH-LEVEL TIMINGS:
--------------------------------------------------------------------------------
data_loading......................................     0.0002 ms
descriptor_extraction_dest........................   430.4981 ms
descriptor_extraction_source......................   238.2122 ms
model_forward.....................................    17.0722 ms
loss_backward.....................................   906.0510 ms
optimizer_step....................................    12.5217 ms
total_iteration...................................  1607.6661 ms

MODEL FORWARD PASS BREAKDOWN:
--------------------------------------------------------------------------------
extract_object_descriptors........................     0.0131 ms
dest_dense_feats_preparation......................     0.2693 ms
cross_attention_source_to_dest....................     5.2621 ms
source_dense_feats_preparation....................     0.2340 ms
cross_attention_dest_to_source....................     5.5262 ms
mlp_source_descriptors............................     0.4457 ms
mlp_dest_descriptors..............................     0.6148 ms
descriptor_normalization..........................     0.3499 ms
similarity_computation............................     0.6159 ms
best_mask_selection...............................     0.2060 ms
topk_selection....................................     1.7356 ms
full_pred_mask_extraction.........................     0.0136 ms
loss_computation..................................     1.2303 ms
sigmoid_activation................................     0.3222 ms
total_forward_pass................................    16.8437 ms

CROSS ATTENTION MODULE #1 (Source to Dest) BREAKDOWN:
--------------------------------------------------------------------------------
norm_input........................................     0.2399 ms
query_projection..................................     0.0667 ms
key_projection....................................     1.2557 ms
value_projection..................................     1.4291 ms
attention_matmul_and_scale........................     1.5840 ms
attention_softmax.................................     0.3980 ms
attention_weighted_sum............................     0.0858 ms
output_projection.................................     0.0758 ms
residual_add......................................     0.0002 ms
feedforward_mlp...................................     0.1112 ms
total_context_attn................................     5.2522 ms

CROSS ATTENTION MODULE #2 (Dest to Source) BREAKDOWN:
--------------------------------------------------------------------------------
norm_input........................................     0.8372 ms
query_projection..................................     0.2006 ms
key_projection....................................     1.3180 ms
value_projection..................................     1.5504 ms
attention_matmul_and_scale........................     0.6953 ms
attention_softmax.................................     0.0915 ms
attention_weighted_sum............................     0.3005 ms
output_projection.................................     0.1700 ms
residual_add......................................     0.0000 ms
feedforward_mlp...................................     0.3480 ms
total_context_attn................................     5.5175 ms

MLP MODULE TIMINGS:
--------------------------------------------------------------------------------
MLP call #1............................................     0.4285 ms
MLP call #2............................................     0.5765 ms

================================================================================
SUMMARY:
--------------------------------------------------------------------------------
Total iteration time: 1607.6661 ms
Model forward pass: 17.0722 ms (1.1% of total)
Total descriptor extraction: 668.7103 ms (41.6% of total)
================================================================================
